{"paragraphs":[{"text":"%md\n## Jeu de donnees\nThe Global Database of Events, Language, and Tone (*GDELT*), est une initiative pour construire un catalogue de comportements et de croyances sociales à travers le monde, reliant chaque personne, organisation, lieu, dénombrement, thème, source d'information, et événement à travers la planète en un seul réseau massif qui capture ce qui se passe dans le monde, le contexte, les implications ainsi que la perception des gens sur chaque jour.\n\n\nCette base de données a eu beaucoup d'utilisations, par exemple pour mieux comprendre l'évolution et l'impact de la crise financière du 2008 (https://arxiv.org/pdf/1403.2272v1.pdf[Bayesian dynamic financial networks with time-varying predictors]) ou analyser l'évolution des relations entre des pays impliquées dans des conflits (http://www.gao.ece.ufl.edu/GXU/fun_reading/sbp_hurst.pdf[Massive Media Event Data Analysis to Assess World-Wide Political Conflict and Instability] ).\n\nGDELT est compose par trois jeux de fichiers CSV, avec un fichier compressé par tranche de 15 minutes:\n\n* les events (https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.events?tab=schema[schema], http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf[CAMEO Ontology], http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation])\n* les mentions (https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.eventmentions[schema], http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation])\n* le graph des relations => GKG, Global Knowledge Graph (https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.gkg[schema], http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.1.pdf[documentation])\n\nL'ensemble des donnees _GDELT_ sont disponibles via HTTP. Un fichier CSV _masterfilelist.txt_\n(http://data.gdeltproject.org/gdeltv2/masterfilelist.txt[Master CSV data file list]) nous permmet d'avoir la liste de tous les fichiers du jeu de donnees GDELT ainsi que l'URL pour telecharger chaque fichier.\n\n\nPour plus d'infos sur le format des fichiers vous pouvez consulter la documentation GDELT: https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\n","user":"anonymous","dateUpdated":"2021-01-21T16:23:40+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Jeu de donnees</h2>\n<p>The Global Database of Events, Language, and Tone (*GDELT*), est une initiative pour construire un catalogue de comportements et de croyances sociales à travers le monde, reliant chaque personne, organisation, lieu, dénombrement, thème, source d&rsquo;information, et événement à travers la planète en un seul réseau massif qui capture ce qui se passe dans le monde, le contexte, les implications ainsi que la perception des gens sur chaque jour.</p>\n<p>Cette base de données a eu beaucoup d&rsquo;utilisations, par exemple pour mieux comprendre l&rsquo;évolution et l&rsquo;impact de la crise financière du 2008 (<a href=\"https://arxiv.org/pdf/1403.2272v1.pdf[Bayesian\">https://arxiv.org/pdf/1403.2272v1.pdf[Bayesian</a> dynamic financial networks with time-varying predictors]) ou analyser l&rsquo;évolution des relations entre des pays impliquées dans des conflits (<a href=\"http://www.gao.ece.ufl.edu/GXU/fun_reading/sbp_hurst.pdf[Massive\">http://www.gao.ece.ufl.edu/GXU/fun_reading/sbp_hurst.pdf[Massive</a> Media Event Data Analysis to Assess World-Wide Political Conflict and Instability] ).</p>\n<p>GDELT est compose par trois jeux de fichiers CSV, avec un fichier compressé par tranche de 15 minutes:</p>\n<ul>\n  <li>les events (<a href=\"https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.events?tab=schema[schema]\">https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.events?tab=schema[schema]</a>, <a href=\"http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf[CAMEO\">http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf[CAMEO</a> Ontology], <a href=\"http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation]\">http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation]</a>)</li>\n  <li>les mentions (<a href=\"https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.eventmentions[schema]\">https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.eventmentions[schema]</a>, <a href=\"http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation]\">http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf[documentation]</a>)</li>\n  <li>le graph des relations =&gt; GKG, Global Knowledge Graph (<a href=\"https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.gkg[schema]\">https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.gkg[schema]</a>, <a href=\"http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.1.pdf[documentation]\">http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.1.pdf[documentation]</a>)</li>\n</ul>\n<p>L&rsquo;ensemble des donnees <em>GDELT</em> sont disponibles via HTTP. Un fichier CSV <em>masterfilelist.txt</em><br/>(<a href=\"http://data.gdeltproject.org/gdeltv2/masterfilelist.txt[Master\">http://data.gdeltproject.org/gdeltv2/masterfilelist.txt[Master</a> CSV data file list]) nous permmet d&rsquo;avoir la liste de tous les fichiers du jeu de donnees GDELT ainsi que l&rsquo;URL pour telecharger chaque fichier.</p>\n<p>Pour plus d&rsquo;infos sur le format des fichiers vous pouvez consulter la documentation GDELT: <a href=\"https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\">https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166594_229960097","id":"20181212-100610_115068599","dateCreated":"2021-01-21T16:22:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:256","dateFinished":"2021-01-21T16:23:40+0000","dateStarted":"2021-01-21T16:23:40+0000"},{"text":"%md\nDans ce notebook nous allons telecharger les fichiers GDELT pourle mois de janvier 2020\nOn commence par definir une function fileDownloder qui telecharge un fichier a partir d’un URL.","user":"anonymous","dateUpdated":"2021-01-21T16:24:57+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Dans ce notebook nous allons telecharger les fichiers GDELT pourle mois de janvier 2020<br/>On commence par definir une function fileDownloder qui telecharge un fichier a partir d’un URL.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166595_-2115362997","id":"20210115-150918_1218358968","dateCreated":"2021-01-21T16:22:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:257","dateFinished":"2021-01-21T16:24:57+0000","dateStarted":"2021-01-21T16:24:57+0000"},{"text":"import sys.process._\nimport java.net.URL\nimport java.io.File\nimport java.io.File\nimport java.nio.file.{Files, StandardCopyOption}\nimport java.net.HttpURLConnection \nimport org.apache.spark.sql.functions._\n\n\n\ndef fileDownloader(urlOfFileToDownload: String, fileName: String) = {\n    val url = new URL(urlOfFileToDownload)\n    val connection = url.openConnection().asInstanceOf[HttpURLConnection]\n    connection.setConnectTimeout(5000)\n    connection.setReadTimeout(5000)\n    connection.connect()\n\n    if (connection.getResponseCode >= 400)\n        println(\"error\")\n    else\n        url #> new File(fileName) !!\n}","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one feature warning; re-run with -feature for details\nimport sys.process._\nimport java.net.URL\nimport java.io.File\nimport java.io.File\nimport java.nio.file.{Files, StandardCopyOption}\nimport java.net.HttpURLConnection\nimport org.apache.spark.sql.functions._\nfileDownloader: (urlOfFileToDownload: String, fileName: String)Any\n"}]},"apps":[],"jobName":"paragraph_1611246166595_-2062371607","id":"20181209-161931_737140067","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:258"},{"text":"%md\nOn peut tester cette fonction pour telecharger en local le *masterfilelist* GDELT.","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>On peut tester cette fonction pour telecharger en local le <em>masterfilelist</em> GDELT.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166596_874285714","id":"20181212-101024_1671681559","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:259"},{"text":"fileDownloader(\"http://data.gdeltproject.org/gdeltv2/masterfilelist.txt\", \"/tmp/masterfilelist.txt\") // save the list file to the Spark Master\nfileDownloader(\"http://data.gdeltproject.org/gdeltv2/masterfilelist-translation.txt\", \"/tmp/masterfilelist_translation.txt\") ","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1611246166596_1437677134","id":"20210108-151447_1571874638","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:260"},{"text":"import com.amazonaws.auth.BasicAWSCredentials\nimport com.amazonaws.services.s3.AmazonS3Client\nimport com.amazonaws.auth.BasicSessionCredentials\n\n\nval AWS_ID = \"ASIAV333OTEUJ23PMQWA\"\nval AWS_KEY = \"Mm40tunM/LlYRhSD+FfxMRcYfIAsy3YurMdhGTCH\"\nval AWS_SESSION_KEY = \"FwoGZXIvYXdzEJ///////////wEaDKUMQ0SfRogYUOfQ+CLMATUegjcVVYTSUG7rvhk0sqyoBT/NT9IR3dIdpy5GGmycEgZNkKX97Nki1g7rphabQaU6cxsDE1sWfMATeuV8cDov3VvjewsCf3votf4zL+ZrZ5KUCHMcENoGRoPwAXoq8Q62TDDlyMlqXrS1F/KAr6j4TvN5aM/z3I3iNJ/3SIBS5U8xQIaJmAlz3nr9Exq9BBcXWklabeWeYuVSHLjkEqmpT+lWFg7RecaUKm7apABUE1pmjtMOWEXDmsRuEuhf2zciDitMpvJ4lMUTjSjNgZiABjItv/k0cqirqhPI1dqY7eqtGvk4f5OEiQApJqcECNQWfiwM49+nZPA7p5JkY8cQ\"\n\n\n// la classe AmazonS3Client n'est pas serializable\n// on rajoute l'annotation @transient pour dire a Spark de ne pas essayer de serialiser cette classe et l'envoyer aux executeurs\n@transient val awsClient = new AmazonS3Client(new BasicSessionCredentials(AWS_ID, AWS_KEY, AWS_SESSION_KEY))\n\nsc.hadoopConfiguration.set(\"fs.s3.access.key\", AWS_ID) // mettre votre ID du fichier credentials.csv\nsc.hadoopConfiguration.set(\"fs.s3.secret.key\", AWS_KEY) // mettre votre secret du fichier credentials.csv\nsc.hadoopConfiguration.set(\"fs.s3.session.token\", AWS_SESSION_KEY)\nsc.hadoopConfiguration.set(\"fs.s3.connection.maximum\",\"100\")","user":"anonymous","dateUpdated":"2021-01-21T16:25:17+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\nimport com.amazonaws.auth.BasicAWSCredentials\nimport com.amazonaws.services.s3.AmazonS3Client\nimport com.amazonaws.auth.BasicSessionCredentials\nAWS_ID: String = ASIAV333OTEUJ23PMQWA\nAWS_KEY: String = Mm40tunM/LlYRhSD+FfxMRcYfIAsy3YurMdhGTCH\nAWS_SESSION_KEY: String = FwoGZXIvYXdzEJ///////////wEaDKUMQ0SfRogYUOfQ+CLMATUegjcVVYTSUG7rvhk0sqyoBT/NT9IR3dIdpy5GGmycEgZNkKX97Nki1g7rphabQaU6cxsDE1sWfMATeuV8cDov3VvjewsCf3votf4zL+ZrZ5KUCHMcENoGRoPwAXoq8Q62TDDlyMlqXrS1F/KAr6j4TvN5aM/z3I3iNJ/3SIBS5U8xQIaJmAlz3nr9Exq9BBcXWklabeWeYuVSHLjkEqmpT+lWFg7RecaUKm7apABUE1pmjtMOWEXDmsRuEuhf2zciDitMpvJ4lMUTjSjNgZiABjItv/k0cqirqhPI1dqY7eqtGvk4f5OEiQApJqcECNQWfiwM49+nZPA7p5JkY8cQ\nawsClient: com.amazonaws.services.s3.AmazonS3Client = com.amazonaws.services.s3.AmazonS3Client@34051546\n"}]},"apps":[],"jobName":"paragraph_1611246166596_212404518","id":"20210108-154829_1456507241","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:261"},{"text":"awsClient.putObject(\"gdelt-adrien-senet-telecom-2020-2\", \"masterfilelist.txt\", new File( \"/tmp/masterfilelist.txt\") )\nawsClient.putObject(\"gdelt-adrien-senet-telecom-2020-2\", \"masterfilelist_translation.txt\", new File( \"/tmp/masterfilelist_translation.txt\") )\n","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"com.amazonaws.SdkClientException: Unable to calculate MD5 hash: /tmp/masterfilelist.txt (No such file or directory)\n  at com.amazonaws.services.s3.AmazonS3Client.getInputStream(AmazonS3Client.java:1887)\n  at com.amazonaws.services.s3.AmazonS3Client.uploadObject(AmazonS3Client.java:1805)\n  at com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1784)\n  at com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1715)\n  ... 52 elided\nCaused by: java.io.FileNotFoundException: /tmp/masterfilelist.txt (No such file or directory)\n  at java.io.FileInputStream.open0(Native Method)\n  at java.io.FileInputStream.open(FileInputStream.java:195)\n  at java.io.FileInputStream.<init>(FileInputStream.java:138)\n  at com.amazonaws.util.Md5Utils.computeMD5Hash(Md5Utils.java:97)\n  at com.amazonaws.util.Md5Utils.md5AsBase64(Md5Utils.java:104)\n  at com.amazonaws.services.s3.AmazonS3Client.getInputStream(AmazonS3Client.java:1883)\n  ... 55 more\n"}]},"apps":[],"jobName":"paragraph_1611246166597_634945039","id":"20210108-153607_653137186","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:262"},{"text":"%md Verifions que le fichier a bien ete uploade dans le bucket S3 via un dataframe Spark","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Verifions que le fichier a bien ete uploade dans le bucket S3 via un dataframe Spark</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166597_1575185713","id":"20181212-101258_954978327","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:263"},{"text":"import org.apache.spark.sql.SQLContext\n\nval sqlContext = new SQLContext(sc)\nval filesDF = sqlContext.read.\n                    option(\"delimiter\",\" \").\n                    option(\"infer_schema\",\"true\").\n                    csv(\"s3://gdelt-adrien-senet-telecom-2020-2/masterfilelist.txt\").\n                    withColumnRenamed(\"_c0\",\"size\").\n                    withColumnRenamed(\"_c1\",\"hash\").\n                    withColumnRenamed(\"_c2\",\"url\").\n                    cache\n\nval files_trans_DF = sqlContext.read.\n                    option(\"delimiter\",\" \").\n                    option(\"infer_schema\",\"true\").\n                    csv(\"s3://gdelt-adrien-senet-telecom-2020-2/masterfilelist_translation.txt\").\n                    withColumnRenamed(\"_c0\",\"size\").\n                    withColumnRenamed(\"_c1\",\"hash\").\n                    withColumnRenamed(\"_c2\",\"url\").\n                    cache","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\nimport org.apache.spark.sql.SQLContext\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@4a2465d9\nfilesDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nfiles_trans_DF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1611246166598_1989770696","id":"20210104-145302_1978135487","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:264"},{"text":"%md Par la suite on va charger uniquement les fichiers qui correspond aux journées d'un mois de l'année 2020 (ici le mois de janvier 2020)","user":"anonymous","dateUpdated":"2021-01-21T16:26:01+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Par la suite on va charger uniquement les fichiers qui correspond aux journées d&rsquo;un mois de l&rsquo;année 2020 (ici le mois de janvier 2020)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166598_1666005225","id":"20181212-101345_616653479","dateCreated":"2021-01-21T16:22:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:265","dateFinished":"2021-01-21T16:26:01+0000","dateStarted":"2021-01-21T16:26:01+0000"},{"text":"val sampleDF = filesDF.filter(col(\"url\").contains(\"/202001\")).cache\nval sample_trans_DF = files_trans_DF.filter(col(\"url\").contains(\"/202001\")).cache\n\nval sampleDF_U = sampleDF.union(sample_trans_DF)","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sampleDF_1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsample_trans_DF_1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsampleDF_2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsample_trans_DF_2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsampleDF_3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsample_trans_DF_3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, hash: string ... 1 more field]\nsampleDF_U: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [size: string, ha..."}]},"apps":[],"jobName":"paragraph_1611246166599_1097606458","id":"20181209-162427_816541907","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:266"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1611246387215_-972174320","id":"20210121-162627_1210142650","dateCreated":"2021-01-21T16:26:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1828","text":"%md Affichage des fichiers GDELT du mois de janvier 2020","dateUpdated":"2021-01-21T16:27:07+0000","dateFinished":"2021-01-21T16:27:07+0000","dateStarted":"2021-01-21T16:27:07+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Affichage des fichiers GDELT du mois de janvier 2020</p>\n</div>"}]}},{"text":"sampleDF_U.show(false)","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------------------------------+--------------------------------------------------------------------+\n|size   |hash                            |url                                                                 |\n+-------+--------------------------------+--------------------------------------------------------------------+\n|162032 |f7a7e782ee56c9eee521b232e1f8a52e|http://data.gdeltproject.org/gdeltv2/20200101000000.export.CSV.zip  |\n|131781 |b68d3a524f3238bdd48ea4fa10976ae8|http://data.gdeltproject.org/gdeltv2/20200101000000.mentions.CSV.zip|\n|5288568|cfa2331d641aca029fea28bebb462ed4|http://data.gdeltproject.org/gdeltv2/20200101000000.gkg.csv.zip     |\n|142044 |dea3910f2cebdb760c2b7078d56eaed4|http://data.gdeltproject.org/gdeltv2/20200101001500.export.CSV.zip  |\n|137798 |304b5e7f2b40e43aedf13daf97b65276|http://data.gdeltproject.org/gdeltv2/20200101001500.mentions.CSV.zip|\n|5437792|75aa9ac51f0be01e66efdfbb9585c387|http://data.gdeltproject.org/gdeltv2/20200101001500.gkg.csv.zip     |\n|164195 |b5192a9feffb91b229c6330a9d962ded|http://data.gdeltproject.org/gdeltv2/20200101003000.export.CSV.zip  |\n|187091 |fea84df20fb59b6b50df9562eea9819e|http://data.gdeltproject.org/gdeltv2/20200101003000.mentions.CSV.zip|\n|6602370|5fd933e1ee4c1868a3cf2e83db36aa4b|http://data.gdeltproject.org/gdeltv2/20200101003000.gkg.csv.zip     |\n|129729 |b3fa65db5c1a0e67d8cf8a02d35feb78|http://data.gdeltproject.org/gdeltv2/20200101004500.export.CSV.zip  |\n|171831 |e3ae5543d2fb7def611bd50bc853c965|http://data.gdeltproject.org/gdeltv2/20200101004500.mentions.CSV.zip|\n|6403012|be5b58fe4030862517f5ace0e280919d|http://data.gdeltproject.org/gdeltv2/20200101004500.gkg.csv.zip     |\n|78272  |2ad5a09905d691f04b03a43ea683afcc|http://data.gdeltproject.org/gdeltv2/20200101010000.export.CSV.zip  |\n|106076 |3d6bbdfa63641e4445bf6ee503ab7385|http://data.gdeltproject.org/gdeltv2/20200101010000.mentions.CSV.zip|\n|4713167|4e30ead7b6c5cab3db022132cbdc39de|http://data.gdeltproject.org/gdeltv2/20200101010000.gkg.csv.zip     |\n|81950  |57d9361121f20e0e10f95565cc2bbfca|http://data.gdeltproject.org/gdeltv2/20200101011500.export.CSV.zip  |\n|120028 |32655f37cfcbc8199adc7eaba6ec54ed|http://data.gdeltproject.org/gdeltv2/20200101011500.mentions.CSV.zip|\n|4914763|fa7137466247b4ab59a0db15b794b24d|http://data.gdeltproject.org/gdeltv2/20200101011500.gkg.csv.zip     |\n|103282 |319c8a47a606ea782edf7d2a06824e39|http://data.gdeltproject.org/gdeltv2/20200101013000.export.CSV.zip  |\n|140959 |b306911ec34d6510594ef1a2a3b266e0|http://data.gdeltproject.org/gdeltv2/20200101013000.mentions.CSV.zip|\n+-------+--------------------------------+--------------------------------------------------------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1611246166599_-252812750","id":"20210117-194727_2002390367","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:267"},{"text":"%md Ci-dessous le nombre de fichiers à charger dans S3 pour le mois choisi.","user":"anonymous","dateUpdated":"2021-01-21T16:28:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Ci-dessous le nombre de fichiers à charger dans S3 pour le mois choisi.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166599_-1800570447","id":"20210121-122531_831348764","dateCreated":"2021-01-21T16:22:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:268","dateFinished":"2021-01-21T16:28:00+0000","dateStarted":"2021-01-21T16:28:00+0000"},{"text":"sampleDF_U.count()","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res15: Long = 52389\n"}]},"apps":[],"jobName":"paragraph_1611246166600_1356479741","id":"20210117-200823_977822991","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:269"},{"text":"%md Nous allons charger tous ces fichiers dans le bucket S3 via un ETL Spark:","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Nous allons charger tous ces fichiers dans le bucket S3 via un ETL Spark:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166600_-1334695897","id":"20181212-101426_1390220831","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:270"},{"text":"// test avec nouveau bucket gdelt-adrien-senet-telecom-2020-2 au lieu de adrien-senet-telecom-gdelt2020\n// car l'autre bucket est rempli avec 1 an de data ce qui ralentit les requetes lors de la lecture des données\n\nobject AwsClient{\n    val s3 = new AmazonS3Client(new BasicSessionCredentials(AWS_ID, AWS_KEY, AWS_SESSION_KEY))\n}\n\nsampleDF_U.select(\"url\").repartition(100).foreach( r=> {\n            val URL = r.getAs[String](0)\n            val fileName = r.getAs[String](0).split(\"/\").last\n            val dir = \"/mnt/tmp/\"\n            val localFileName = dir + fileName\n            fileDownloader(URL,  localFileName)\n            val localFile = new File(localFileName)\n            AwsClient.s3.putObject(\"gdelt-adrien-senet-telecom-2020-2\", \"2020-12/\" + fileName, localFile )\n            localFile.delete()\n})","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\ndefined object AwsClient\n"}]},"apps":[],"jobName":"paragraph_1611246166601_-1649641736","id":"20181209-163933_1336720866","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:271"},{"text":"%md\nWell done! Vous pouvez maintenaient explorer les donnees via le notebook gdeltExploration.json","user":"anonymous","dateUpdated":"2021-01-21T16:22:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Well done! Vous pouvez maintenaient explorer les donnees via le notebook gdeltExploration.json</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1611246166601_-1999201551","id":"20181212-100557_635513911","dateCreated":"2021-01-21T16:22:46+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:272"}],"name":"Gdelt ETL 2021","id":"2FVSZ1B46","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}